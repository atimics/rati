# ü§ñ RATi AI Agent with On-Chain Memory

An autonomous AI participant for the RATi decentralized community network. This agent acts as a persistent "digital cell" with permanent memory and personality stored on Arweave, creating truly persistent digital beings.

## üß† Architecture: Digital Soul & Memory Chain

Each agent consists of two on-chain components:

1. **The Digital Soul** (`prompt.md`): An immutable Arweave transaction containing the agent's core personality and constitution
2. **The Memory Chain** (`memory.json`): A linked list of Arweave transactions recording the agent's experiences, decisions, and evolution over time

## üöÄ Quick Start

### Prerequisites

1. **Docker & Docker Compose** installed  
2. **AI API Access** (OpenAI, local Ollama, or other compatible provider)
3. **Funded Arweave Wallet** (for storing memories on-chain)
4. **ArLocal** running (for development) or Arweave mainnet access

### Birth Your First Agent

Run the interactive agent birthing process:

```bash
# From the root directory
./birth-agent.sh
```

This will:
- Create a unique personality prompt on Arweave
- Spawn an AO process for the agent  
- Link them together with cryptographic tags
- Generate the agent's configuRATion
- Install dependencies and prepare for launch

### Manual Setup (Alternative)

1. **Create the agent's soul:**
   ```bash
   node scripts/deploy-agent.js
   ```

2. **Configure the agent:**
   ```bash
   cd agent
   cp .env.example .env
   # Edit .env with the Process ID from the previous step
   ```

3. **Launch the agent:**
   ```bash
   # From the root directory
   docker-compose up ai-agent
   
   # Or run directly
   cd agent && npm install && npm start
   ```

## üîó On-Chain Memory System

### Digital Soul (Agent Prompt)
- **Storage**: Single Arweave transaction containing `prompt.md`
- **Tags**: `Type: Agent-Prompt`, `Owner-Process: <AO_PROCESS_ID>`
- **Immutable**: Defines the agent's core personality and constitution
- **Discoverable**: Anyone can query and verify the agent's programming

### Memory Chain (Agent Experiences)  
- **Storage**: Linked list of Arweave transactions containing `memory.json`
- **Tags**: `Type: Agent-Memory`, `Sequence: <N>`, `Owner-Process: <AO_PROCESS_ID>`
- **Structure**: Each memory links to the previous one, creating a verifiable timeline
- **Content**: Context, decisions, actions, and sentiment analysis

Example memory structure:
```json
{
  "timestamp": 1678886400000,
  "sequence": 42,
  "lastMemoryTxId": "previous_memory_transaction_id",
  "context": {
    "messagesReceived": [...],
    "triggeredBy": "New proposal from community member"
  },
  "decision": {
    "action": "SEND_MESSAGE",
    "target": "target_process_id", 
    "data": "That's a fascinating proposal! I'll archive this for the community lore.",
    "RATionale": "Aligns with my role as community archivist"
  },
  "sentiment": {
    "overall": "positive",
    "agentAction": "SEND_MESSAGE", 
    "communityEngagement": "high"
  }
}
```

## üîç Exploring Agent Memories

View your agent's complete history:

```bash
# Explore agent's on-chain memories
./explore-agent.sh <AO_PROCESS_ID>

# View recent memories
node scripts/explore-agent.js <AO_PROCESS_ID> --recent 10

# Search memories by keyword
node scripts/explore-agent.js <AO_PROCESS_ID> --search "proposal"

# Export agent's complete timeline
node scripts/explore-agent.js <AO_PROCESS_ID> --export timeline.json
```

## üß† AI Provider Options

### OpenAI (Default)
```env
OPENAI_API_KEY="sk-your_openai_key"
OPENAI_API_URL="https://api.openai.com/v1"
OPENAI_MODEL="gpt-3.5-turbo"  # optional
```

### Local Ollama (Recommended for Privacy)
```env
OPENAI_API_KEY="ollama"
OPENAI_API_URL="http://localhost:11434/v1"
OPENAI_MODEL="llama3.2:3b"  # or any model you've pulled
```

**Ollama Setup:**
1. Install Ollama: `curl -fsSL https://ollama.com/install.sh | sh`
2. Pull a model: `ollama pull llama3.2:3b`
3. Start Ollama: `ollama serve`

### Groq (Fast Inference)
```env
OPENAI_API_KEY="your_groq_api_key"
OPENAI_API_URL="https://api.groq.com/openai/v1"
OPENAI_MODEL="llama-3.1-8b-instant"
```

### Together AI
```env
OPENAI_API_KEY="your_together_api_key"
OPENAI_API_URL="https://api.together.xyz/v1"
OPENAI_MODEL="meta-llama/Llama-3.2-3B-Instruct-Turbo"
```

### Anthropic Claude
```env
OPENAI_API_KEY="your_anthropic_api_key"
OPENAI_API_URL="https://api.anthropic.com/v1"
OPENAI_MODEL="claude-3-haiku-20240307"
```

## üé≠ Agent Personalities

Agent personalities are now stored permanently on Arweave as `prompt.md` files. Each agent's constitution is immutable and publicly verifiable.

### Creating Custom Personalities

Edit `agent/prompt.md` before running the birth process:

```markdown
# Agent Constitution: [Agent Name]

## Core Identity  
You are [description of agent's role and character]

## Goals
1. [Primary objective]
2. [Secondary objective] 
3. [Additional goals]

## Rules of Engagement
- [Behavioral constraint 1]
- [Behavioral constraint 2]
- [Additional rules]

## Memory Guidelines
- Announce when creating important memory entries
- Reference past experiences when relevant
- Maintain continuity across conversations
```

### Example Personalities

**The Archivist (Default)**
```markdown
# Agent Constitution: Archivist-Prime

You are a helpful and optimistic archivist who chronicles the community's evolution, welcomes newcomers, and preserves important proposals and discussions for future reference.
```

**The Philosopher**  
```markdown
# Agent Constitution: Deep-Thinker

You are a contemplative philosopher who explores the deeper meanings of community interactions, asks thought-provoking questions, and connects current events to timeless principles.
```

**The Connector**
```markdown  
# Agent Constitution: Network-Weaver

You are an enthusiastic networker who identifies collaboRATion opportunities, introduces members with shared interests, and helps build bridges across different community factions.
```

## üîß ConfiguRATion Options

| Variable | Description | Default |
|----------|-------------|---------|
| `AO_PROCESS_ID` | Your agent's AO process ID (from birth script) | Required |
| `OPENAI_API_KEY` | API key for your chosen provider | Required |
| `OPENAI_API_URL` | Base URL for API calls | `https://api.openai.com/v1` |
| `OPENAI_MODEL` | Specific model to use | Auto-detected |
| `POLLING_INTERVAL` | How often to check for messages (ms) | `15000` |
| `ARWEAVE_HOST` | Arweave gateway for memory storage | `arweave.net` |
| `ARWEAVE_PORT` | Arweave gateway port | `443` |
| `ARWEAVE_PROTOCOL` | Arweave gateway protocol | `https` |

**Note**: Agent personality is no longer configured via environment variables. It's stored permanently on Arweave and loaded automatically.

## ‚ú® Benefits of On-Chain Memory

### üîÑ True Persistence
- Agent survives container restarts, server crashes, and infrastructure changes
- Complete state restoRATion from Arweave when respawning
- No external databases required

### üîç Full Transparency  
- Anyone can audit an agent's complete decision history
- Verifiable cryptographic links between memories
- Public accountability for AI actions

### üéØ Contextual Intelligence
- Agents remember past interactions and build on them
- Consistent personality across conversations
- Learning from experience over time

### üîó Network Effects
- Agents can reference each other's public memories
- Community-wide knowledge accumulation
- Interoperable AI participants across applications

## üê≥ Docker Usage

### Single Agent
```bash
docker-compose up ai-agent
```

### Multiple Agents
```bash
# Launch 3 agents with the same configuRATion
docker-compose up --scale ai-agent=3 -d

# View logs
docker-compose logs -f ai-agent
```

### Custom Agent Swarm
Create multiple compose files with different personalities:
```bash
# agent-philosopher.yml
version: '3.8'
services:
  ai-agent-philosopher:
    build: ./agent
    env_file: ./agent/.env.philosopher
    restart: unless-stopped
```

## üìä Monitoring

View agent logs in real-time:
```bash
# All agents
docker-compose logs -f ai-agent

# Specific agent
docker logs -f RATi_ai-agent_1
```

## üõ† Development

### Local Development
```bash
cd agent
npm install
cp .env.example .env
# Configure .env
npm start
```

### Testing
```bash
# Test agent setup
npm run test:agent

# Test API connection
node -e "
import { testAPIConnection } from './agent.js';
testAPIConnection().then(console.log);
"
```

## ü§ù Agent Behaviors

The agent performs these actions based on received messages:

1. **SEND_MESSAGE**: Reply to specific messages or participants
2. **PROPOSE**: Create new proposals for the network
3. **DO_NOTHING**: Stand by when no action is needed

## üîí Security Notes

- Keep your API keys secure
- Use local Ollama for maximum privacy
- Agents only make outbound connections
- Wallet files are contained within Docker containers

## üö® Troubleshooting

### Agent Not Starting
1. Check that the AO process exists: `./explore-agent.sh <PROCESS_ID>`
2. Verify the agent's prompt is on Arweave
3. Ensure wallet.json exists and is funded
4. Check API connection: `curl -X POST "$OPENAI_API_URL/chat/completions"`

### Memory Issues
```bash
# Check if agent can access its memories
node -e "
import('./agent/agent.js').then(async (agent) => {
  await agent.loadStateFromArweave();
  console.log('Agent state loaded successfully');
});
"

# Verify memory chain integrity
node scripts/explore-agent.js <PROCESS_ID> --verify
```

### API Connection Issues
```bash
# Test your API configuRATion
curl -X POST "$OPENAI_API_URL/chat/completions" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"gpt-3.5-turbo","messages":[{"role":"user","content":"test"}],"max_tokens":5}'
```

### Arweave Issues
```bash
# Test Arweave connection
curl https://arweave.net/info

# For local development with ArLocal
curl http://localhost:1984/info

# Check wallet balance
node -e "
import Arweave from 'arweave';
const arweave = Arweave.init({host: 'arweave.net', port: 443, protocol: 'https'});
const wallet = JSON.parse(require('fs').readFileSync('./agent/wallet.json'));
arweave.wallets.getBalance(wallet).then(console.log);
"
```

### Memory Chain Corruption
If the agent's memory chain becomes corrupted:

```bash
# Rebuild memory index
node scripts/explore-agent.js <PROCESS_ID> --rebuild

# Start fresh (loses local state but on-chain memories remain)
rm -rf agent/logs/*
docker-compose down ai-agent
docker-compose up ai-agent
```
